#!/usr/bin/env python3

"""
MIT License

Copyright (c) 2023 Alex Gunter <akg7634@gmail.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""


import argparse
import configparser
from dataclasses import dataclass
from datetime import datetime
import hashlib
from itertools import groupby
import os
from pathlib import Path, PurePath
import platform
import re
import shutil
import subprocess   # used to try to automatically find Nolla_Games_Noita location
import typing
from xml.etree import ElementTree


__version_info__ = ('0', '9', '2')
__version__ = '.'.join(__version_info__)

__config_name__ = "noitabm.ini"
__config_path__ = Path(__file__).parent.resolve() / __config_name__


@dataclass
class ToolConfig:
    f"""
    Loaded from {__config_name__}, or automatically created if that file doesn't exist.
    
    Keeps track of configured paths and can also generate other necessary paths.
    """

    noita_data_path: Path
    backup_data_path: Path

    @staticmethod
    def load() -> 'ToolConfig':
        with open(__config_path__, 'r') as fobj:
            config = configparser.ConfigParser()
            config.read_file(fobj)
            path_args = {k: Path(p).resolve() for k, p in config["PATHS"].items()}
            return ToolConfig(**path_args)

    def write(self):
        parser = configparser.ConfigParser()
        parser.read_dict({"PATHS": self.__dict__})

        with open(__config_path__, 'w') as fobj:
            parser.write(fobj)

    def slot_path(self, slot_id: int) -> Path:
        return self.noita_data_path / f"save{slot_id:02d}"

    def world_state_path(self, slot_id: int) -> Path:
        return self.slot_path(slot_id) / "world_state.xml"

    def backup_path(self, session_id: str, backup_id: str) -> Path:
        return self.backup_data_path / f"{session_id}_{backup_id}"


class IdLib:
    """
    A collection of functions for generating identifiers.
    """

    @staticmethod
    def new_id() -> str:
        return datetime.now().strftime("%Y%m%d-%H%M%S")

    @staticmethod
    def extract_session_id(tool_config: ToolConfig, slot_id: int) -> str:
        state_path = tool_config.world_state_path(slot_id)
        try:
            tree = ElementTree.parse(state_path)
            session_string = (
                tree.getroot()
                    .find('WorldStateComponent')
                    .attrib['session_stat_file']
            )
            return re.findall(r"^\?\?STA/sessions/([0-9]{8}-[0-9]{6})$", session_string)[0]
        except FileNotFoundError as err:
            print(f"Session ID lookup failed: {state_path.relative_to(tool_config.noita_data_path)} doesn't exist")
            raise err

    @staticmethod
    def hash_directory(base_path: Path, ignore: typing.Set[str] = None) -> str:
        """
        Constructs a git-style SHA1 hash for a directory.
        Hash will change if files are added, renamed or modified.
        Specific files and paths can be omitted.

        :param base_path: the directory to hash
        :param ignore: a set of patterns to ignore. Expects basic .gitignore patterns.
        :return: a git-style SHA1 hash representing the directory's contents
        """

        ignore = {} if ignore is None else ignore
        path_filehash_pairs: typing.Dict[str, bytes] = {}

        # Iterate through directory
        # Add (relative_path, file_hash) pairs to lookup table
        for subdir, dirs, files in os.walk(base_path.resolve()):
            for fname in files:
                full_path = Path(subdir).resolve() / fname
                relative_path = PurePath("/") / full_path.relative_to(base_path)
                relative_path = str(relative_path.as_posix())

                with open(full_path, 'rb') as fobj:
                    fhash = hashlib.sha1(fobj.read()).digest()
                    path_filehash_pairs[relative_path] = fhash

        # Iterate through (relative_path, file_hash) pairs in alphanumeric order
        # Add all pairs to hasher and return cumulative hash
        dir_hash_obj = hashlib.sha1()
        for rpath in sorted(path_filehash_pairs.keys()):
            found_in_ignore = False
            for patt in ignore:
                patt = re.sub(r"^/", r"^/", patt)
                patt = re.sub(r"\.", r"\.", patt)
                patt = re.sub(r"\*", r".", patt)
                if re.search(patt, rpath) is not None:
                    found_in_ignore = True
                    break

            if found_in_ignore:
                continue

            dir_hash_obj.update(os.fsencode(rpath))
            dir_hash_obj.update(os.fsencode("\n"))
            dir_hash_obj.update(path_filehash_pairs[rpath])
            dir_hash_obj.update(os.fsencode("\n"))

        return dir_hash_obj.hexdigest()

    @staticmethod
    def short_hash(long_hash: str) -> str:
        return long_hash[:7]


@dataclass
class BackupInfo:
    session_id: str
    backup_id: str
    contents_hash: str
    description: str

    @staticmethod
    def _get_info_path(backup_root_path: Path) -> Path:
        return backup_root_path / "backup_info.txt"

    @staticmethod
    def path_contains_backup(backup_root_path: Path) -> bool:
        return BackupInfo._get_info_path(backup_root_path).exists()

    @staticmethod
    def from_root_path(backup_root_path: Path) -> 'BackupInfo':
        config_path = BackupInfo._get_info_path(backup_root_path)
        config = configparser.ConfigParser()
        config.read(config_path)
        return BackupInfo(**config['INFO'])

    @staticmethod
    def construct_contents_hash(save_data_path: Path) -> str:
        return IdLib.hash_directory(save_data_path, ignore={"/backup_info.txt"})

    @property
    def contents_shorthash(self) -> str:
        return IdLib.short_hash(self.contents_hash)

    def backup_path(self, tool_config: ToolConfig) -> Path:
        return tool_config.backup_path(self.session_id, self.backup_id)

    def info_path(self, tool_config: ToolConfig) -> Path:
        return BackupInfo._get_info_path(self.backup_path(tool_config))

    def write(self, tool_config: ToolConfig):
        parser = configparser.ConfigParser()
        parser.read_dict({"INFO": self.__dict__})

        with open(self.info_path(tool_config), 'w') as fobj:
            parser.write(fobj)


class ConfigCommands:
    @staticmethod
    def _guess_noita_path() -> typing.Optional[Path]:
        system = platform.system().lower()

        if system == "windows":
            homedir = Path.home()
            noita_dir = homedir / "AppData" / "LocalLow" / "Nolla_Games_Noita"
            return noita_dir if noita_dir.exists() else None
        elif system == "linux":
            try:
                # WSL logic
                cmd = ['wslvar', 'USERPROFILE']
                winpath = subprocess.run(cmd, check=True, shell=False, capture_output=True, text=True).stdout.strip()
                cmd = ['wslpath', winpath]
                wslpath = subprocess.run(cmd, check=True, shell=False, capture_output=True, text=True).stdout.strip()
                noita_dir = Path(wslpath) / "AppData" / "LocalLow" / "Nolla_Games_Noita"
                return noita_dir if noita_dir.exists() else None
            except subprocess.CalledProcessError:
                # true Linux logic

                # GOG: ???
                # Humble Store: ???
                # itch.io: ???

                # Handles Steam installations
                homedir = Path.home()
                noita_dir = homedir / ".local" / "share" / "Steam" / "steamapps" / "compatdata"
                noita_dir = noita_dir / "881100" / "pfx" / "drive_c" / "users" / "steamuser"
                noita_dir = noita_dir / "AppData" / "LocalLow" / "Nolla_Games_Noita"
                return noita_dir if noita_dir.exists() else None

        elif system == "darwin":
            # I have absolutely no clue where Noita's data goes in a Mac install.
            return None

        else:
            # When in doubt, return None
            return None

    @staticmethod
    def _init_with_prompt(args: argparse.Namespace) -> ToolConfig:
        noita_data_path = (
            None if not hasattr(args, "noita_data_path")
            else None if args.noita_data_path is None
            else Path(args.noita_data_path)
        )
        backup_data_path = (
            None if not hasattr(args, "backup_data_path")
            else None if args.backup_data_path is None
            else Path(args.backup_data_path)
        )

        if noita_data_path is None:
            guessed_path = ConfigCommands._guess_noita_path()
            if guessed_path is not None:
                msg = f"Enter the path to Noita's save data [{guessed_path}]:\n"
            else:
                msg = "Enter the path to Noita's save data (i.e. Nolla_Games_Noita):\n"
            noita_data_path = input(msg)
            noita_data_path = guessed_path if noita_data_path == "" else guessed_path
            noita_data_path = Path(noita_data_path).resolve()

        if backup_data_path is None:
            default_backup_path = noita_data_path / "backups"
            msg = f"\nEnter your desired backup storage location [{default_backup_path}]:\n"
            backup_data_path = input(msg)
            backup_data_path = default_backup_path if backup_data_path == "" else backup_data_path
            backup_data_path = Path(backup_data_path).resolve()

        tool_config = ToolConfig(
            noita_data_path=noita_data_path,
            backup_data_path=backup_data_path
        )
        tool_config.write()

        return tool_config

    @staticmethod
    def get_or_create_config(args: argparse.Namespace) -> ToolConfig:
        try:
            return ToolConfig.load()
        except IOError:
            print(f"Config not found at {__config_path__}. Creating a new one...\n")
            ConfigCommands._init_with_prompt(args)
            return ToolConfig.load()

    @staticmethod
    def print_config(tool_config: ToolConfig):
        print(f"Displaying values from {__config_path__}:")
        for k, v in sorted(tool_config.__dict__.items()):
            print(f"    {k}: {v}")

    @staticmethod
    def edit_config(tool_config: ToolConfig, args: argparse.Namespace):
        if args.noita_data_path is not None:
            tool_config.noita_data_path = Path(args.noita_data_path).resolve()

        if args.backup_data_path is not None:
            tool_config.backup_data_path = Path(args.backup_data_path).resolve()

        tool_config.write()

        print("Config updated")
        ConfigCommands.print_config(tool_config)


class ListCommands:
    @staticmethod
    def retrieve_all_backup_info(tool_config: ToolConfig) -> typing.List[BackupInfo]:
        try:
            paths = [
                tool_config.backup_data_path / p
                for p in tool_config.backup_data_path.iterdir()
            ]
            return [
                BackupInfo.from_root_path(p) for p in paths
                if p.is_dir() and BackupInfo.path_contains_backup(p)
            ]

        except FileNotFoundError:
            return []

    @staticmethod
    def retrieve_session_ids(tool_config: ToolConfig) -> typing.List[str]:
        all_backup_info = ListCommands.retrieve_all_backup_info(tool_config)
        return list(sorted({b.session_id for b in all_backup_info}))

    @staticmethod
    def retrieve_session_backup_info(tool_config: ToolConfig, session_id: str) -> typing.List[BackupInfo]:
        return [
            b for b in ListCommands.retrieve_all_backup_info(tool_config)
            if b.session_id == session_id
        ]

    @staticmethod
    def print_selected_backup_info(selected_backup_info: typing.List[BackupInfo]):
        if len(selected_backup_info) == 0:
            print("No backups found...")
            return

        selected_backup_info = groupby(selected_backup_info, lambda b: b.session_id)
        selected_backup_info = {k: list(sorted(v, key=lambda b: b.backup_id)) for k, v in selected_backup_info}
        selected_session_ids = list(sorted(selected_backup_info.keys()))

        # go ahead and count how many of everything we have
        num_sessions = len(selected_session_ids)
        num_backups = sum(len(b) for b in selected_backup_info.values())

        session_id_header = "SESSION ID"
        session_id_maxlen = max(len(session_id_header), max(len(sid) for sid in selected_session_ids))
        backup_id_header = "BACKUP ID"
        backup_id_maxlen = max(
            len(backup_id_header),
            max(len(b.backup_id) for b_inf in selected_backup_info.values() for b in b_inf)
        )
        shorthash_header = "SHORT HASH"
        shorthash_maxlen = max(len(shorthash_header), 7)
        # longhash_header = "LONG HASH"
        # longhash_maxlen = max(len(longhash_header), 40)
        desc_header = "DESCRIPTION"
        header_str = (
                "    " +
                session_id_header + " " * (session_id_maxlen - len(session_id_header)) + "    " +
                backup_id_header + " " * (backup_id_maxlen - len(backup_id_header)) + "    " +
                shorthash_header + " " * (shorthash_maxlen - len(shorthash_header)) + "    " +
                # longhash_header + " " * (longhash_maxlen - len(longhash_header)) + "    " +
                desc_header
        )

        print(f"Displaying {num_backups} backup(s) across {num_sessions} session(s):\n")
        print(header_str)
        print("    " + "-" * (session_id_maxlen + backup_id_maxlen + shorthash_maxlen + len(desc_header) + 12))
        for session_id in sorted(selected_session_ids):
            backup_info = selected_backup_info[session_id]
            if len(backup_info) == 0:
                pass

            b0 = backup_info[0]
            first_info_string = (
                    "    " +
                    b0.session_id + " " * (session_id_maxlen - len(b0.session_id)) + "    " +
                    b0.backup_id + " " * (backup_id_maxlen - len(b0.backup_id)) + "    " +
                    b0.contents_shorthash + " " * (shorthash_maxlen - len(b0.contents_shorthash)) + "    " +
                    # b0.contents_hash + " " * (longhash_maxlen - len(b.contents_hash)) + "    " +
                    b0.description
            )
            print(first_info_string)

            if len(backup_info) >= 2:
                remaining_info_strings = [
                    "    " +
                    " " * backup_id_maxlen + "    " +
                    b.backup_id + " " * (backup_id_maxlen - len(b.backup_id)) + "    " +
                    b.contents_shorthash + " " * (shorthash_maxlen - len(b.contents_shorthash)) + "    " +
                    # b0.contents_hash + " " * (longhash_maxlen - len(b.contents_hash)) + "    " +
                    b.description
                    for b in backup_info[1:]
                ]
                for s in remaining_info_strings:
                    print(s)

    @staticmethod
    def print_session_backup_info(tool_config: ToolConfig, args: argparse.Namespace):
        session_id = args.session_id
        selected_backup_info = ListCommands.retrieve_session_backup_info(tool_config, session_id)

        if len(selected_backup_info) == 0:
            print(f"No backups found for session {session_id}...")
            return

        ListCommands.print_selected_backup_info(selected_backup_info)


    @staticmethod
    def print_past_backups(tool_config: ToolConfig, args: argparse.Namespace):
        # retrieve backups and session id's
        all_backup_info = ListCommands.retrieve_all_backup_info(tool_config)
        all_backup_info = list(sorted(all_backup_info, key=lambda b: b.session_id))

        # when using -n and -b, truncate the selection
        if args.n is None:
            selected_backup_info = all_backup_info
        elif args.b:
            selected_backup_info = all_backup_info[-args.n:]
        else:
            all_session_ids = list(sorted(set(b.session_id for b in all_backup_info)))
            selected_session_ids = all_session_ids[-args.n:]
            selected_backup_info = [b for b in all_backup_info if b.session_id in set(selected_session_ids)]

        ListCommands.print_selected_backup_info(selected_backup_info)


class BackupCommands:
    @staticmethod
    def create_new_backup(tool_config: ToolConfig, slot_id: int, description: str):
        slot_path = tool_config.slot_path(slot_id)

        try:
            session_id = IdLib.extract_session_id(tool_config, slot_id)
        except FileNotFoundError as err:
            print("Backup failed: try using Save and Quit in-game to initialize world data")
            raise err

        backup_id = IdLib.new_id()
        contents_hash = BackupInfo.construct_contents_hash(slot_path)

        backup_info = BackupInfo(
            session_id=session_id,
            backup_id=backup_id,
            contents_hash=contents_hash,
            description=description
        )
        backup_path = backup_info.backup_path(tool_config)

        print(f"Creating new backup...")

        existing_hashes = {
            b.contents_hash: b
            for b in ListCommands.retrieve_session_backup_info(tool_config, session_id)
        }
        if contents_hash in existing_hashes:
            b = existing_hashes[contents_hash]
            print(f"Slot {slot_id} has already been backed up.")
            print(f"    Existing Session ID: {b.session_id}")
            print(f"    Existing Backup ID: {b.backup_id}")
            print(f"    Existing Short Hash: {b.contents_shorthash}")
            print(f"    Existing Long Hash: {b.contents_hash}")
            print(f"    Existing Description: {b.description}")
            return

        print(f"    Slot ID: {slot_id}")
        print(f"    Session ID: {backup_info.session_id}")
        print(f"    Backup ID: {backup_info.backup_id}")
        print(f"    Short Hash: {backup_info.contents_shorthash}")
        print(f"    Long Hash: {backup_info.contents_hash}")
        print(f"    Description: {backup_info.description}")
        print(f"    Src: {slot_path}")
        print(f"    Dst: {backup_path}")
        print(f"    Info: {backup_info.info_path(tool_config)}")
        shutil.copytree(slot_path, backup_path)
        backup_info.write(tool_config)

        print("\n    Backup complete")

    @staticmethod
    def run_backup_command(tool_config: ToolConfig, args: argparse.Namespace):
        try:
            BackupCommands.create_new_backup(tool_config, args.slot_id, args.description)
        except FileNotFoundError:
            return


class RestoreCommands:
    @staticmethod
    def restore_backup(tool_config: ToolConfig, args: argparse.Namespace):
        def get_key(b: BackupInfo):
            return (
                b.backup_id if args.backup_id is not None
                else b.contents_shorthash if args.short_hash is not None
                else b.contents_hash
            )

        key = next(x for x in (args.backup_id, args.short_hash, args.long_hash) if x is not None)
        existing_backups = {
            get_key(b): b
            for b in ListCommands.retrieve_session_backup_info(tool_config, args.session_id)
        }

        if key not in existing_backups:
            word = (
                "backup ID" if args.backup_id is not None
                else "short-hash" if args.short_hash is not None
                else "long-hash"
            )
            print(f"No backup found for session ID {args.session_id} and {word} {key}")
            return

        if not args.skip_restore_point:
            try:
                description = f"Automatic backup of Slot {args.slot_id}"
                BackupCommands.create_new_backup(tool_config, args.slot_id, description)
            except FileNotFoundError:
                print("Restoration failed: unable to create restore point")
                return

        source_backup = existing_backups[key]
        source_path = source_backup.backup_path(tool_config)
        target_path = tool_config.slot_path(args.slot_id)

        print(f"Cleaning Slot {args.slot_id}..")
        shutil.rmtree(target_path)
        print(f"Restoring backup to Slot {args.slot_id}...")
        shutil.copytree(source_path, target_path)
        print("Restoration complete")


class ModifyCommands:
    @staticmethod
    def recalc_hash(tool_config: ToolConfig, backup_info: BackupInfo):
        new_hash = BackupInfo.construct_contents_hash(backup_info.backup_path(tool_config))
        backup_info.contents_hash = new_hash

    @staticmethod
    def modify_all(tool_config: ToolConfig, args: argparse.Namespace):
        if args.hash_all:
            print("Recomputing all hashes. This may take a while...")
            all_backups = ListCommands.retrieve_all_backup_info(tool_config)
            for backup_info in all_backups:
                ModifyCommands.recalc_hash(tool_config, backup_info)
            print("Complete")

    @staticmethod
    def modify_backup(tool_config: ToolConfig, args: argparse.Namespace):
        selected_backups = ListCommands.retrieve_session_backup_info(tool_config, args.session_id)

        if args.backup_id is not None:
            backup_info = next(filter(lambda b: b.backup_id == args.backup_id, selected_backups))
        elif args.short_hash is not None:
            backup_info = next(filter(lambda b: b.contents_shorthash == args.short_hash, selected_backups))
        else:
            backup_info = next(filter(lambda b: b.contents_hash == args.long_hash, selected_backups))

        print("Found specified backup:")
        print(f"    Session ID: {backup_info.session_id}")
        print(f"    Backup ID: {backup_info.backup_id}")
        print(f"    Short Hash: {backup_info.contents_shorthash}")
        print(f"    Long Hash: {backup_info.contents_hash}")
        print(f"    Description: {backup_info.description}")

        if args.hash:
            print("Recalculating hash...")
            ModifyCommands.recalc_hash(tool_config, backup_info)

        if args.description is not None:
            print("Updating description...")
            backup_info.description = args.description

        backup_info.write(tool_config)

        reloaded_backup_info = BackupInfo.from_root_path(backup_info.backup_path(tool_config))
        print("\nSuccessfully updated backup:")
        print(f"    Session ID: {reloaded_backup_info.session_id}")
        print(f"    Backup ID: {reloaded_backup_info.backup_id}")
        print(f"    Short Hash: {reloaded_backup_info.contents_shorthash}")
        print(f"    Long Hash: {reloaded_backup_info.contents_hash}")
        print(f"    Description: {reloaded_backup_info.description}")


class DeleteCommands:
    @staticmethod
    def run_session_delete(tool_config: ToolConfig, args: argparse.Namespace):
        selected_backups = ListCommands.retrieve_session_backup_info(tool_config, args.session_id)
        ListCommands.print_selected_backup_info(selected_backups)

        paths_to_delete = [b.backup_path(tool_config) for b in selected_backups]
        print(f"\nWill delete {len(paths_to_delete)} paths:")
        for p in paths_to_delete:
            print(f"    {p}")

        response = input("\nCONFIRM [y/N]: ").lower()
        if response == 'y' or response == 'yes':
            print(f"Deleting {len(paths_to_delete)} paths...")
            for p in paths_to_delete:
                shutil.rmtree(p)
            print("Deletion complete")
        elif response == 'n' or response == 'no':
            print("Backup not deleted")
        else:
            print("Ignoring input, expected y/yes or n/no")
            print("Backup not deleted")

    @staticmethod
    def run_backup_delete(tool_config: ToolConfig, args: argparse.Namespace):
        selected_backups = ListCommands.retrieve_session_backup_info(tool_config, args.session_id)

        if args.backup_id is not None:
            backup_info = next(filter(lambda b: b.backup_id == args.backup_id, selected_backups))
        elif args.short_hash is not None:
            backup_info = next(filter(lambda b: b.contents_shorthash == args.short_hash, selected_backups))
        else:
            backup_info = next(filter(lambda b: b.contents_hash == args.long_hash, selected_backups))

        print("Found specified backup:")
        print(f"    Session ID: {backup_info.session_id}")
        print(f"    Backup ID: {backup_info.backup_id}")
        print(f"    Short Hash: {backup_info.contents_shorthash}")
        print(f"    Long Hash: {backup_info.contents_hash}")
        print(f"    Description: {backup_info.description}")

        path_to_delete = backup_info.backup_path(tool_config)
        print(f"\nPath to delete: {path_to_delete}")
        response = input("\nCONFIRM [y/N]: ").lower()
        if response == 'y' or response == 'yes':
            print(f"Deleting {path_to_delete}...")
            shutil.rmtree(path_to_delete)
            print("Deletion complete")
        elif response == 'n' or response == 'no':
            print("Backup not deleted")
        else:
            print("Ignoring input, expected y/yes or n/no")
            print("Backup not deleted")


# === PARSER SETUP ===
def init_parser():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    parser.add_argument(
        "--version",
        action='version',
        version=f'%(prog)s {__version__}'
    )

    # === CONFIG COMMANDS ===
    config_parser = subparsers.add_parser("config", help=f"set {__config_name__} values from the command line")
    config_subparsers = config_parser.add_subparsers()
    # = config print =
    config_print_parser = config_subparsers.add_parser(
        "print",
        help=f"print the contents and location of {__config_name__}",
    )
    config_print_parser.set_defaults(func=lambda t, a: ConfigCommands.print_config(t))
    # = config edit =
    config_edit_parser = config_subparsers.add_parser(
        "edit",
        help="edit config values"
    )
    config_edit_group = config_edit_parser.add_argument_group("modifiables")
    config_edit_group.add_argument(
        "--noita-data-path",
        help="set the path to Noita's save data (i.e. Nolla_Games_Noita)",
        type=str
    )
    config_edit_group.add_argument(
        "--backup-data-path",
        help="set your desired backup storage location",
        type=str
    )
    config_parser.set_defaults(func=ConfigCommands.edit_config)

    # === LIST COMMANDS ===
    list_parser = subparsers.add_parser("list", help="list available session IDs, backup IDs, and hashes")
    # = list =
    list_parser.add_argument(
        "-b",
        help="when paired with -n, swaps to last N backups",
        action="store_true"
    )
    list_parser.add_argument(
        "-n",
        help="show only the last N sessions",
        type=int
    )
    list_parser.set_defaults(func=ListCommands.print_past_backups)

    list_subparsers = list_parser.add_subparsers()
    # = list session =
    list_session_parser = list_subparsers.add_parser("session", help="display backups for a specific session ID")
    list_session_parser.add_argument(
        "session_id",
        type=str
    )
    list_session_parser.set_defaults(func=ListCommands.print_session_backup_info)

    # === BACKUP COMMANDS ===
    backup_parser = subparsers.add_parser("backup", help="create a new backup from the specified slot")
    backup_parser.add_argument(
        "slot_id",
        help="the save slot to backup (default: 0)",
        type=int,
        nargs='?',
        choices=list(range(7)),
        default=0,
        const=0
    )
    backup_parser.add_argument(
        "-d", "--description",
        help="Add a description to the backup, so you can easily identify it later",
        type=str,
        default=""
    )
    backup_parser.set_defaults(func=BackupCommands.run_backup_command)

    # === RESTORE COMMANDS ===
    restore_parser = subparsers.add_parser("restore", help="restore the specified backup to the specified slot")
    restore_parser.add_argument(
        "session_id",
        help="the session ID to restore",
        type=str,
    )
    restore_group = restore_parser.add_mutually_exclusive_group(required=True)
    restore_group.add_argument(
        "-b", "--backup_id",
        help="the backup ID to restore",
        type=str,
    )
    restore_group.add_argument(
        "-s", "--short-hash",
        help="the short-hash to restore",
        type=str,
    )
    restore_group.add_argument(
        "-l", "--long-hash",
        help="the long-hash to restore",
        type=str,
    )
    restore_parser.add_argument(
        "slot_id",
        help="the save slot to restore to (default: 0)",
        type=int,
        nargs='?',
        choices=list(range(7)),
        default=0,
        const=0
    )
    restore_parser.add_argument(
        "--skip-restore-point",
        help="apply the backup without creating a restore point. CURRENT DATA WILL BE PERMANENTLY LOST.",
        action="store_true"
    )
    restore_parser.set_defaults(func=RestoreCommands.restore_backup)

    # === MODIFY COMMANDS ===
    modify_parser = subparsers.add_parser("modify", help="modify an existing backup in-place")
    modify_subparsers = modify_parser.add_subparsers()
    # = modify all =
    modify_all_parser = modify_subparsers.add_parser("all", help="modify all backups")
    modify_all_parser.add_argument(
        "--hash-all",
        help="recompute all hashes",
        action="store_true"
    )
    modify_all_parser.set_defaults(func=ModifyCommands.modify_all)
    # = modify session =
    #   note: I chose "session" instead of "backup" because "backup" is already an important subcommand
    #   the first argument is also a session id, so this choice makes the command read better as a bonus
    modify_session_parser = modify_subparsers.add_parser("session")
    modify_session_parser.add_argument(
        "session_id",
        help="the session ID to modify",
        type=str,
    )
    modify_identifier_group = modify_session_parser.add_mutually_exclusive_group(required=True)
    modify_identifier_group.add_argument(
        "-b", "--backup_id",
        help="the backup ID to modify",
        type=str,
    )
    modify_identifier_group.add_argument(
        "-s", "--short-hash",
        help="the short-hash to modify",
        type=str,
    )
    modify_identifier_group.add_argument(
        "-l", "--long-hash",
        help="the long-hash to modify",
        type=str,
    )
    modify_session_parser.add_argument(
        "--hash",
        help="recompute the hash for the backup, in case you've modified the contents",
        action="store_true"
    )
    modify_session_parser.add_argument(
        "-d", "--description",
        help="set a new description for the backup, so you can easily identify it later",
        type=str
    )
    modify_parser.set_defaults(func=ModifyCommands.modify_backup)

    # === DELETE COMMANDS ===
    #  note: this subcommand is verbose on purpose, so it's a bit harder to accidentally delete stuff
    delete_parser = subparsers.add_parser("delete", help="delete archived sessions and backups")
    delete_session_subparsers = delete_parser.add_subparsers()
    delete_session_parser = delete_session_subparsers.add_parser(
        "session",
        help="delete all backups for the given session"
    )
    delete_session_parser.add_argument(
        "session_id",
        help="the session ID to delete",
        type=str,
    )
    delete_session_parser.set_defaults(func=DeleteCommands.run_session_delete)

    delete_backup_subparser = delete_session_subparsers.add_parser(
        "backup",
        help="delete a specified backup for a specified session"
    )
    delete_backup_group = delete_backup_subparser.add_argument_group()
    delete_backup_group.add_argument(
        "session_id",
        help="the session ID to modify",
        type=str,
    )
    delete_backup_subgroup = delete_backup_group.add_mutually_exclusive_group(required=True)
    delete_backup_subgroup.add_argument(
        "-b", "--backup_id",
        help="the backup ID to modify",
        type=str,
    )
    delete_backup_subgroup.add_argument(
        "-s", "--short-hash",
        help="the short-hash to modify",
        type=str,
    )
    delete_backup_subgroup.add_argument(
        "-l", "--long-hash",
        help="the long-hash to modify",
        type=str,
    )
    delete_backup_subparser.set_defaults(func=DeleteCommands.run_backup_delete)

    return parser


if __name__ == "__main__":
    # TODO: Add loops/checks for invalid prompt inputs
    # TODO: Add safety checks for collided short hashes
    # TODO: Add safety-confirmation for Nolla_Games_Noita path
    # TODO: Add option to rebuild entire backup_info.txt
    # TODO: Add option to display long hashes in list command

    created_parser = init_parser()
    parsed_args = created_parser.parse_args()

    loaded_tool_config = ConfigCommands.get_or_create_config(parsed_args)

    # I forgot why I added this try/catch block, and now I can't reproduce the error that motivated it.
    # try:
    func = parsed_args.func
    # except AttributeError:
    #     func = None
    #     created_parser.error("too few arguments")

    func(loaded_tool_config, parsed_args)
