#!/usr/bin/env python3

"""
MIT License

Copyright (c) 2023 Alex Gunter <akg7634@gmail.com>

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
"""


import argparse
import configparser
import dataclasses
import datetime
import hashlib
from pathlib import Path, PurePath
import os
import re
import shutil
import subprocess   # used to try to automatically find Nolla_Games_Noita location
import typing
from xml.etree import ElementTree


__version_info__ = ('0', '9', '1')
__version__ = '.'.join(__version_info__)

__config_name__ = "noitabm.ini"
__config_path__ = Path(__file__).parent.resolve() / __config_name__

@dataclasses.dataclass
class ToolConfig:
    f"""
    Loaded from {__config_name__}, or automatically created if that file doesn't exist.
    
    Keeps track of configured paths and can also generate other necessary paths.
    """

    noita_data_path: Path
    backup_data_path: Path

    @staticmethod
    def load() -> 'ToolConfig':
        with open(__config_path__, 'r') as fobj:
            config = configparser.ConfigParser()
            config.read_file(fobj)
            path_args = {k: Path(p).resolve() for k, p in config["PATHS"].items()}
            return ToolConfig(**path_args)

    def write(self):
        parser = configparser.ConfigParser()
        parser.read_dict({"PATHS": self.__dict__})

        with open(__config_path__, 'w') as fobj:
            parser.write(fobj)

    def slot_path(self, slot_id: int) -> Path:
        return self.noita_data_path / f"save{slot_id:02d}"

    def world_state_path(self, slot_id: int) -> Path:
        return self.slot_path(slot_id) / "world_state.xml"

    def backup_path(self, session_id: str, backup_id: str) -> Path:
        return self.backup_data_path / f"{session_id}_{backup_id}"


class IdLib:
    """
    A collection of functions for generating identifiers.
    """

    @staticmethod
    def new_id() -> str:
        return datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

    @staticmethod
    def extract_session_id(tool_config: ToolConfig, slot_id: int) -> str:
        state_path = tool_config.world_state_path(slot_id)
        tree = ElementTree.parse(state_path)
        session_string = (
            tree.getroot()
                .find('WorldStateComponent')
                .attrib['session_stat_file']
        )
        return re.findall(r"^\?\?STA/sessions/([0-9]{8}-[0-9]{6})$", session_string)[0]

    @staticmethod
    def hash_directory(base_path: Path, ignore: typing.Set[str] = None) -> str:
        """
        Constructs a git-style SHA1 hash for a directory.
        Hash will change if files are added, renamed or modified.
        Specific files and paths can be omitted.

        :param base_path: the directory to hash
        :param ignore: a set of patterns to ignore. Expects basic .gitignore patterns.
        :return: a git-style SHA1 hash representing the directory's contents
        """

        ignore = {} if ignore is None else ignore
        path_filehash_pairs: typing.Dict[str, bytes] = {}

        # Iterate through directory
        # Add (relative_path, file_hash) pairs to lookup table
        for subdir, dirs, files in os.walk(base_path.resolve()):
            for fname in files:
                full_path = Path(subdir).resolve() / fname
                relative_path = PurePath("/") / full_path.relative_to(base_path)
                relative_path = str(relative_path.as_posix())

                with open(full_path, 'rb') as fobj:
                    fhash = hashlib.sha1(fobj.read()).digest()
                    path_filehash_pairs[relative_path] = fhash

        # Iterate through (relative_path, file_hash) pairs in alphanumeric order
        # Add all pairs to hasher and return cumulative hash
        dir_hash_obj = hashlib.sha1()
        for rpath in sorted(path_filehash_pairs.keys()):
            found_in_ignore = False
            for patt in ignore:
                patt = re.sub(r"^/", r"^/", patt)
                patt = re.sub(r"\.", r"\.", patt)
                patt = re.sub(r"\*", r".", patt)
                if re.search(patt, rpath) is not None:
                    found_in_ignore = True
                    break

            if found_in_ignore:
                continue

            dir_hash_obj.update(os.fsencode(rpath))
            dir_hash_obj.update(os.fsencode("\n"))
            dir_hash_obj.update(path_filehash_pairs[rpath])
            dir_hash_obj.update(os.fsencode("\n"))

        return dir_hash_obj.hexdigest()

    @staticmethod
    def short_hash(long_hash: str) -> str:
        return long_hash[:7]


@dataclasses.dataclass
class BackupInfo:
    session_id: str
    backup_id: str
    contents_hash: str
    description: str

    @staticmethod
    def _get_info_path(backup_root_path: Path) -> Path:
        return backup_root_path / "backup_info.txt"

    @staticmethod
    def path_contains_backup(backup_root_path: Path) -> bool:
        return BackupInfo._get_info_path(backup_root_path).exists()

    @staticmethod
    def from_root_path(backup_root_path: Path) -> 'BackupInfo':
        config_path = BackupInfo._get_info_path(backup_root_path)
        config = configparser.ConfigParser()
        config.read(config_path)
        return BackupInfo(**config['INFO'])

    @staticmethod
    def construct_contents_hash(save_data_path: Path) -> str:
        return IdLib.hash_directory(save_data_path, ignore={"/backup_info.txt"})

    @property
    def contents_shorthash(self) -> str:
        return IdLib.short_hash(self.contents_hash)

    def backup_path(self, tool_config: ToolConfig) -> Path:
        return tool_config.backup_path(self.session_id, self.backup_id)

    def info_path(self, tool_config: ToolConfig) -> Path:
        return BackupInfo._get_info_path(self.backup_path(tool_config))

    def write(self, tool_config: ToolConfig):
        parser = configparser.ConfigParser()
        parser.read_dict({"INFO": self.__dict__})

        with open(self.info_path(tool_config), 'w') as fobj:
            parser.write(fobj)


class ConfigCommands:
    @staticmethod
    def _guess_noita_path() -> typing.Optional[Path]:
        import platform

        system = platform.system().lower()
        release = platform.release().lower()
        if system == "windows":
            homedir = Path.home()
            noita_dir = homedir / "AppData" / "LocalLow" / "Nolla_Games_Noita"
            return noita_dir if noita_dir.exists() else None
        elif system == "linux":
            try:
                cmd = ['wslvar', 'USERPROFILE']
                winpath = subprocess.run(cmd, check=True, shell=False, capture_output=True, text=True).stdout.strip()
                cmd = ['wslpath', winpath]
                wslpath = subprocess.run(cmd, check=True, shell=False, capture_output=True, text=True).stdout.strip()
                noita_dir = Path(wslpath) / "AppData" / "LocalLow" / "Nolla_Games_Noita"
                return noita_dir if noita_dir.exists() else None
            except subprocess.CalledProcessError:
                # GOG: ???
                # Humble Store: ???
                # itch.io: ???

                # Handles Steam installations
                homedir = Path.home()
                noita_dir = homedir / ".local" / "share" / "Steam" / "steamapps" / "compatdata"
                noita_dir = noita_dir / "881100" / "pfx" / "drive_c" / "users" / "steamuser"
                noita_dir = noita_dir / "AppData" / "LocalLow" / "Nolla_Games_Noita"
                return noita_dir if noita_dir.exists() else None

        elif system == "darwin":
            # I have absolutely no clue where Noita's data goes in a Mac install.
            return None

        else:
            # When in doubt, return None
            return None

    @staticmethod
    def _init_with_prompt(args: argparse.Namespace) -> ToolConfig:
        noita_data_path = (
            None if not hasattr(args, "noita_data_path")
            else None if args.noita_data_path is None
            else Path(args.noita_data_path)
        )
        backup_data_path = (
            None if not hasattr(args, "backup_data_path")
            else None if args.backup_data_path is None
            else Path(args.backup_data_path)
        )

        if noita_data_path is None:
            guessed_path = ConfigCommands._guess_noita_path()
            if guessed_path is not None:
                msg = f"Enter the path to Noita's save data [{guessed_path}]:\n"
            else:
                msg = "Enter the path to Noita's save data (i.e. Nolla_Games_Noita):\n"
            noita_data_path = input(msg)
            noita_data_path = guessed_path if noita_data_path == "" else guessed_path
            noita_data_path = Path(noita_data_path).resolve()

        if backup_data_path is None:
            default_backup_path = noita_data_path / "backups"
            msg = f"\nEnter your desired backup storage location [{default_backup_path}]:\n"
            backup_data_path = input(msg)
            backup_data_path = default_backup_path if backup_data_path == "" else backup_data_path
            backup_data_path = Path(backup_data_path).resolve()

        tool_config = ToolConfig(
            noita_data_path=noita_data_path,
            backup_data_path=backup_data_path
        )
        tool_config.write()

        return tool_config

    @staticmethod
    def get_or_create_config(args: argparse.Namespace) -> ToolConfig:
        try:
            return ToolConfig.load()
        except IOError:
            print(f"Config not found at {__config_path__}. Creating a new one...\n")
            ConfigCommands._init_with_prompt(args)
            return ToolConfig.load()

    @staticmethod
    def print_config(tool_config: ToolConfig):
        print(f"Displaying values from {__config_path__}:")
        for k, v in sorted(tool_config.__dict__.items()):
            print(f"    {k}: {v}")

    @staticmethod
    def edit_config(tool_config: ToolConfig, args: argparse.Namespace):
        if args.noita_data_path is not None:
            tool_config.noita_data_path = Path(args.noita_data_path).resolve()

        if args.backup_data_path is not None:
            tool_config.backup_data_path = Path(args.backup_data_path).resolve()

        tool_config.write()

        print("Config updated")
        ConfigCommands.print_config(tool_config)


class ListCommands:
    @staticmethod
    def retrieve_all_backup_info(tool_config: ToolConfig) -> typing.List[BackupInfo]:
        try:
            paths = [
                tool_config.backup_data_path / p
                for p in tool_config.backup_data_path.iterdir()
            ]
            return [
                BackupInfo.from_root_path(p) for p in paths
                if p.is_dir() and BackupInfo.path_contains_backup(p)
            ]

        except FileNotFoundError:
            return []

    @staticmethod
    def retrieve_session_ids(tool_config: ToolConfig) -> typing.List[str]:
        all_backup_info = ListCommands.retrieve_all_backup_info(tool_config)
        return list(sorted({b.session_id for b in all_backup_info}))

    @staticmethod
    def retrieve_session_backup_info(tool_config: ToolConfig, session_id: str) -> typing.List[BackupInfo]:
        return [
            b for b in ListCommands.retrieve_all_backup_info(tool_config)
            if b.session_id == session_id
        ]

    @staticmethod
    def print_session_id_list(session_info: typing.List[str]):
        if len(session_info) == 0:
            print("No backups found...")
            return

        print(f"Found backups for {len(session_info)} session(s):\n")
        print("    SESSION ID")
        print("    ----------")
        for s in sorted(session_info):
            print(f"    {s}")

    @staticmethod
    def print_session_backup_info(session_id: int, backup_info: typing.List[BackupInfo]):
        if len(backup_info) == 0:
            print(f"No backups found for session {session_id}...")
            return

        backup_id_header = "BACKUP ID"
        backup_id_maxlen = max(len(backup_id_header), max(len(b.backup_id) for b in backup_info))
        shorthash_header = "SHORT HASH"
        shorthash_maxlen = max(len(shorthash_header), 7)
        # longhash_header = "LONG HASH"
        # longhash_maxlen = max(len(longhash_header), 40)
        desc_header = "DESCRIPTION"
        header_str = (
                "    " +
                backup_id_header + " " * (backup_id_maxlen - len(backup_id_header)) + "    " +
                shorthash_header + " " * (shorthash_maxlen - len(shorthash_header)) + "    " +
                # longhash_header + " " * (longhash_maxlen - len(longhash_header)) + "    " +
                desc_header
        )

        backup_info_strings = [
            "    " +
            b.backup_id + " " * (backup_id_maxlen - len(b.backup_id)) + "    " +
            b.contents_shorthash + " " * (shorthash_maxlen - len(b.contents_shorthash)) + "    " +
            # b.contents_hash + " " * (longhash_maxlen - len(b.contents_hash)) + "    " +
            b.description
            for b in backup_info
        ]

        print(f"Found {len(backup_info)} backups for session {session_id}:\n")
        print(header_str)
        print("    " + "-" * (backup_id_maxlen + shorthash_maxlen + len(desc_header) + 8))
        for b_str in sorted(backup_info_strings):
            print(b_str)

    @staticmethod
    def print_all_backup_info(tool_config: ToolConfig):
        from itertools import groupby

        all_backup_info = list(sorted(ListCommands.retrieve_all_backup_info(tool_config), key=lambda b: b.session_id))
        all_backup_info = groupby(all_backup_info, lambda b: b.session_id)
        all_backup_info = {k: list(sorted(v, key=lambda b: b.backup_id)) for k, v in all_backup_info}
        session_info = list(sorted(all_backup_info.keys()))

        num_sessions = len(session_info)
        num_backups = sum(len(b) for b in all_backup_info.values())

        session_id_header = "SESSION ID"
        session_id_maxlen = max(len(session_id_header), max(len(sid) for sid in session_info))
        backup_id_header = "BACKUP ID"
        backup_id_maxlen = max(
            len(backup_id_header),
            max(len(b.backup_id) for b_inf in all_backup_info.values() for b in b_inf)
        )
        shorthash_header = "SHORT HASH"
        shorthash_maxlen = max(len(shorthash_header), 7)
        # longhash_header = "LONG HASH"
        # longhash_maxlen = max(len(longhash_header), 40)
        desc_header = "DESCRIPTION"
        header_str = (
                "    " +
                session_id_header + " " * (session_id_maxlen - len(session_id_header)) + "    " +
                backup_id_header + " " * (backup_id_maxlen - len(backup_id_header)) + "    " +
                shorthash_header + " " * (shorthash_maxlen - len(shorthash_header)) + "    " +
                # longhash_header + " " * (longhash_maxlen - len(longhash_header)) + "    " +
                desc_header
        )

        print(f"Displaying {num_backups} backup(s) across {num_sessions} session(s):\n")
        print(header_str)
        print("    " + "-" * (session_id_maxlen + backup_id_maxlen + shorthash_maxlen + len(desc_header) + 12))
        for session_id in sorted(session_info):
            backup_info = all_backup_info[session_id]
            if len(backup_info) == 0:
                pass

            b0 = backup_info[0]
            first_info_string = (
                    "    " +
                    b0.session_id + " " * (session_id_maxlen - len(b0.session_id)) + "    " +
                    b0.backup_id + " " * (backup_id_maxlen - len(b0.backup_id)) + "    " +
                    b0.contents_shorthash + " " * (shorthash_maxlen - len(b0.contents_shorthash)) + "    " +
                    # b0.contents_hash + " " * (longhash_maxlen - len(b.contents_hash)) + "    " +
                    b0.description
            )
            print(first_info_string)

            if len(backup_info) >= 2:
                remaining_info_strings = [
                    "    " +
                    " " * backup_id_maxlen + "    " +
                    b.backup_id + " " * (backup_id_maxlen - len(b.backup_id)) + "    " +
                    b.contents_shorthash + " " * (shorthash_maxlen - len(b.contents_shorthash)) + "    " +
                    # b0.contents_hash + " " * (longhash_maxlen - len(b.contents_hash)) + "    " +
                    b.description
                    for b in backup_info[1:]
                ]
                for s in remaining_info_strings:
                    print(s)

    @staticmethod
    def run_list_command(tool_config, args: argparse.Namespace):
        if args.all:
            ListCommands.print_all_backup_info(tool_config)
        elif args.session_id is None:
            session_info = ListCommands.retrieve_session_ids(tool_config)
            ListCommands.print_session_id_list(session_info)
        else:
            selected_backup_info = ListCommands.retrieve_session_backup_info(tool_config, args.session_id)
            ListCommands.print_session_backup_info(args.session_id, selected_backup_info)


class BackupCommands:
    @staticmethod
    def create_new_backup(tool_config: ToolConfig, slot_id: int, description: str):
        slot_path = tool_config.slot_path(slot_id)

        session_id = IdLib.extract_session_id(tool_config, slot_id)
        backup_id = IdLib.new_id()
        contents_hash = BackupInfo.construct_contents_hash(slot_path)

        backup_info = BackupInfo(
            session_id=session_id,
            backup_id=backup_id,
            contents_hash=contents_hash,
            description=description
        )
        backup_path = backup_info.backup_path(tool_config)

        print(f"Creating new backup...")

        existing_hashes = {
            b.contents_hash: b
            for b in ListCommands.retrieve_session_backup_info(tool_config, session_id)
        }
        if contents_hash in existing_hashes:
            b = existing_hashes[contents_hash]
            print(f"Slot {slot_id} has already been backed up.")
            print(f"    Existing Session ID: {b.session_id}")
            print(f"    Existing Backup ID: {b.backup_id}")
            print(f"    Existing Short Hash: {b.contents_shorthash}")
            print(f"    Existing Long Hash: {b.contents_hash}")
            print(f"    Existing Description: {b.description}")
            return

        print(f"    Slot ID: {slot_id}")
        print(f"    Session ID: {backup_info.session_id}")
        print(f"    Backup ID: {backup_info.backup_id}")
        print(f"    Short Hash: {backup_info.contents_shorthash}")
        print(f"    Long Hash: {backup_info.contents_hash}")
        print(f"    Description: {backup_info.description}")
        print(f"    Src: {slot_path}")
        print(f"    Dst: {backup_path}")
        print(f"    Info: {backup_info.info_path(tool_config)}")
        shutil.copytree(slot_path, backup_path)
        backup_info.write(tool_config)

        print("\n    Backup complete")

    @staticmethod
    def run_backup_command(tool_config: ToolConfig, args: argparse.Namespace):
        BackupCommands.create_new_backup(tool_config, args.slot_id, args.description)


class RestoreCommands:
    @staticmethod
    def restore_backup(tool_config: ToolConfig, args: argparse.Namespace):
        def get_key(b: BackupInfo):
            return (
                b.backup_id if args.backup_id is not None
                else b.contents_shorthash if args.short_hash is not None
                else b.contents_hash
            )

        key = next(x for x in (args.backup_id, args.short_hash, args.long_hash) if x is not None)
        existing_backups = {
            get_key(b): b
            for b in ListCommands.retrieve_session_backup_info(tool_config, args.session_id)
        }

        if key not in existing_backups:
            word = (
                "backup ID" if args.backup_id is not None
                else "short-hash" if args.short_hash is not None
                else "long-hash"
            )
            print(f"No backup found for session ID {args.session_id} and {word} {key}")
            return

        if not args.skip_restore_point:
            description = f"Automatic backup of Slot {args.slot_id}"
            BackupCommands.create_new_backup(tool_config, args.slot_id, description)

        source_backup = existing_backups[key]
        source_path = source_backup.backup_path(tool_config)
        target_path = tool_config.slot_path(args.slot_id)

        print(f"Cleaning Slot {args.slot_id}..")
        shutil.rmtree(target_path)
        print(f"Restoring backup to Slot {args.slot_id}...")
        shutil.copytree(source_path, target_path)
        print("Restoration complete")


class ModifyCommands:
    @staticmethod
    def recalc_hash(tool_config: ToolConfig, backup_info: BackupInfo):
        new_hash = BackupInfo.construct_contents_hash(backup_info.backup_path(tool_config))
        backup_info.contents_hash = new_hash

    @staticmethod
    def modify_backup(tool_config: ToolConfig, args: argparse.Namespace):
        if args.hash_all:
            print("Recomputing all hashes. This may take a while...")
            all_backups = ListCommands.retrieve_all_backup_info(tool_config)
            for backup_info in all_backups:
                ModifyCommands.recalc_hash(tool_config, backup_info)
            print("Complete")
            return

        selected_backups = ListCommands.retrieve_session_backup_info(tool_config, args.session_id)

        if args.backup_id is not None:
            backup_info = next(filter(lambda b: b.backup_id == args.backup_id, selected_backups))
        elif args.short_hash is not None:
            backup_info = next(filter(lambda b: b.contents_shorthash == args.short_hash, selected_backups))
        else:
            backup_info = next(filter(lambda b: b.contents_hash == args.long_hash, selected_backups))

        print("Found specified backup:")
        print(f"    Session ID: {backup_info.session_id}")
        print(f"    Backup ID: {backup_info.backup_id}")
        print(f"    Short Hash: {backup_info.contents_shorthash}")
        print(f"    Long Hash: {backup_info.contents_hash}")
        print(f"    Description: {backup_info.description}")

        if args.hash:
            print("Recalculating hash...")
            ModifyCommands.recalc_hash(tool_config, backup_info)

        if args.description is not None:
            print("Updating description...")
            backup_info.description = args.description

        backup_info.write(tool_config)

        reloaded_backup_info = BackupInfo.from_root_path(backup_info.backup_path(tool_config))
        print("\nSuccessfully updated backup:")
        print(f"    Session ID: {reloaded_backup_info.session_id}")
        print(f"    Backup ID: {reloaded_backup_info.backup_id}")
        print(f"    Short Hash: {reloaded_backup_info.contents_shorthash}")
        print(f"    Long Hash: {reloaded_backup_info.contents_hash}")
        print(f"    Description: {reloaded_backup_info.description}")


class DeleteCommands:
    @staticmethod
    def run_session_delete(tool_config: ToolConfig, args: argparse.Namespace):
        print(args)

    @staticmethod
    def run_backup_delete(tool_config: ToolConfig, args: argparse.Namespace):
        print(args)


# === PARSER SETUP ===
def init_parser():
    parser = argparse.ArgumentParser()
    subparsers = parser.add_subparsers()

    parser.add_argument(
        "--version",
        action='version',
        version=f'%(prog)s {__version__}'
    )

    # === CONFIG COMMANDS ===
    config_parser = subparsers.add_parser("config", help=f"set {__config_name__} values from the command line")
    config_subparsers = config_parser.add_subparsers()
    # = PRINT =
    config_print_parser = config_subparsers.add_parser(
        "print",
        help=f"print the contents and location of {__config_name__}",
    )
    config_print_parser.set_defaults(func=lambda t, a: ConfigCommands.print_config(t))
    # = EDIT =
    config_edit_parser = config_subparsers.add_parser(
        "edit",
        help="edit config values"
    )
    config_edit_group = config_edit_parser.add_argument_group("modifiables")
    config_edit_group.add_argument(
        "--noita-data-path",
        help="set the path to Noita's save data (i.e. Nolla_Games_Noita)",
        type=str
    )
    config_edit_group.add_argument(
        "--backup-data-path",
        help="set your desired backup storage location",
        type=str
    )
    config_parser.set_defaults(func=ConfigCommands.edit_config)

    # === LIST COMMANDS ===
    list_parser = subparsers.add_parser("list", help="list available session IDs or backup IDs")
    list_group = list_parser.add_mutually_exclusive_group()
    list_group.add_argument(
        "-a", "--all",
        help="list all backups for all sessions",
        action="store_true"
    )
    list_group.add_argument(
        "session_id",
        help="list backup IDs for the specified session ID",
        type=str,
        nargs='?'
    )
    list_parser.set_defaults(func=ListCommands.run_list_command)

    # === BACKUP COMMANDS ===
    backup_parser = subparsers.add_parser("backup", help="create a new backup from the specified slot")
    backup_parser.add_argument(
        "slot_id",
        help="the save slot to backup (default: 0)",
        type=int,
        nargs='?',
        choices=list(range(7)),
        default=0,
        const=0
    )
    backup_parser.add_argument(
        "-d", "--description",
        help="Add a description to the backup, so you can easily identify it later",
        type=str,
        default=""
    )
    backup_parser.set_defaults(func=BackupCommands.create_new_backup)

    # === RESTORE COMMANDS ===
    restore_parser = subparsers.add_parser("restore", help="restore the specified backup to the specified slot")
    restore_parser.add_argument(
        "session_id",
        help="the session ID to restore",
        type=str,
    )
    restore_group = restore_parser.add_mutually_exclusive_group(required=True)
    restore_group.add_argument(
        "-b", "--backup_id",
        help="the backup ID to restore",
        type=str,
    )
    restore_group.add_argument(
        "-s", "--short-hash",
        help="the short-hash to restore",
        type=str,
    )
    restore_group.add_argument(
        "-l", "--long-hash",
        help="the long-hash to restore",
        type=str,
    )
    restore_parser.add_argument(
        "slot_id",
        help="the save slot to restore to (default: 0)",
        type=int,
        nargs='?',
        choices=list(range(7)),
        default=0,
        const=0
    )
    restore_parser.add_argument(
        "--skip-restore-point",
        help="apply the backup without creating a restore point. CURRENT DATA WILL BE PERMANENTLY LOST.",
        action="store_true"
    )
    restore_parser.set_defaults(func=RestoreCommands.restore_backup)

    # === MODIFY COMMANDS ===
    modify_parser = subparsers.add_parser("modify", help="modify an existing backup in-place")
    modify_parser.add_argument(
        "--hash-all",
        help="recompute all hashes",
        action="store_true"
    )

    modify_subparsers = modify_parser.add_subparsers()
    modify_session_parser = modify_subparsers.add_parser("session")
    modify_session_parser.add_argument(
        "session_id",
        help="the session ID to modify",
        type=str,
    )
    modify_identifier_group = modify_session_parser.add_mutually_exclusive_group(required=True)
    modify_identifier_group.add_argument(
        "-b", "--backup_id",
        help="the backup ID to modify",
        type=str,
    )
    modify_identifier_group.add_argument(
        "-s", "--short-hash",
        help="the short-hash to modify",
        type=str,
    )
    modify_identifier_group.add_argument(
        "-l", "--long-hash",
        help="the long-hash to modify",
        type=str,
    )
    modify_session_parser.add_argument(
        "--hash",
        help="recompute the hash for the backup, in case you've modified the contents",
        action="store_true"
    )
    modify_session_parser.add_argument(
        "-d", "--description",
        help="set a new description for the backup, so you can easily identify it later",
        type=str
    )
    modify_parser.set_defaults(func=ModifyCommands.modify_backup)

    # === DELETE COMMANDS ===
    delete_parser = subparsers.add_parser("delete", help="delete archived sessions and backups")
    delete_session_subparsers = delete_parser.add_subparsers()
    delete_session_parser = delete_session_subparsers.add_parser(
        "session",
        help="delete all backups for the given session"
    )
    delete_session_parser.add_argument(
        "session_id",
        help="the session ID to delete",
        type=str,
    )
    delete_session_parser.set_defaults(func=DeleteCommands.run_session_delete)

    delete_backup_subparser = delete_session_subparsers.add_parser(
        "backup",
        help="delete a specified backup for a specified session"
    )
    delete_backup_group = delete_backup_subparser.add_argument_group()
    delete_backup_group.add_argument(
        "session_id",
        help="the session ID to modify",
        type=str,
    )
    delete_backup_subgroup = delete_backup_group.add_mutually_exclusive_group(required=True)
    delete_backup_subgroup.add_argument(
        "-b", "--backup_id",
        help="the backup ID to modify",
        type=str,
    )
    delete_backup_subgroup.add_argument(
        "-s", "--short-hash",
        help="the short-hash to modify",
        type=str,
    )
    delete_backup_subgroup.add_argument(
        "-l", "--long-hash",
        help="the long-hash to modify",
        type=str,
    )
    delete_backup_subparser.set_defaults(func=DeleteCommands.run_backup_delete)

    # TODO: Implement delete operations
    # TODO: Refactor other commands to use more commands and fewer arguments

    return parser


if __name__ == "__main__":
    created_parser = init_parser()
    parsed_args = created_parser.parse_args()

    loaded_tool_config = ConfigCommands.get_or_create_config(parsed_args)

    # I forgot why I added this try/catch block, and now I can't reproduce the error that motivated it.
    # try:
    func = parsed_args.func
    # except AttributeError:
    #     func = None
    #     created_parser.error("too few arguments")

    func(loaded_tool_config, parsed_args)
